version: "3.6"
services:
  graphql-engine:
    image: hasura/graphql-engine:v2.28.0.cli-migrations-v3
    ports:
      - "8080:8080"
    restart: always
    # todo: automatically load metadata from directory
    volumes:
      - "./hasura:/hasura"
    environment:
      HASURA_GRAPHQL_MIGRATIONS_DIR: /hasura/migrations
      HASURA_GRAPHQL_METADATA_DIR: /hasura/metadata
      # postgres database to store Hasura metadata
      HASURA_GRAPHQL_METADATA_DATABASE_URL: ${PG_DATABASE_URL}
      ## this env var can be used to add the above postgres database to Hasura as a data source. this can be removed/updated based on your needs
      PG_DATABASE_URL: ${PG_DATABASE_URL}
      ## enable the console served by server
      HASURA_GRAPHQL_ENABLE_CONSOLE: "true" # set to "false" to disable console
      ## enable debugging mode. It is recommended to disable this in production
      HASURA_GRAPHQL_DEV_MODE: "true"
      HASURA_GRAPHQL_ENABLED_LOG_TYPES: startup, http-log, webhook-log, websocket-log, query-log
      HASURA_GRAPHQL_ENABLE_ALLOWLIST: "true"
      HASURA_GRAPHQL_UNAUTHORIZED_ROLE: "public"
      HASURA_GRAPHQL_ADMIN_SECRET: ${HASURA_GRAPHQL_ADMIN_SECRET}
      HASURA_GRAPHQL_METADATA_DEFAULTS: '{"backend_configs":{"dataconnector":{"athena":{"uri":"http://data-connector-agent:8081/api/v1/athena"},"mariadb":{"uri":"http://data-connector-agent:8081/api/v1/mariadb"},"mysql8":{"uri":"http://data-connector-agent:8081/api/v1/mysql"},"oracle":{"uri":"http://data-connector-agent:8081/api/v1/oracle"},"snowflake":{"uri":"http://data-connector-agent:8081/api/v1/snowflake"}}}}'
      ## uncomment next line to run console offline (i.e load console assets from server instead of CDN)
      # HASURA_GRAPHQL_CONSOLE_ASSETS_DIR: /srv/console-assets
    depends_on:
      data-connector-agent:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  actions-service:
    build:
      context: ./services/actions-service
      dockerfile: Dockerfile
    ports:
      - "3030:3030"
    environment:
      HASURA_GRAPHQL_ADMIN_SECRET: ${HASURA_GRAPHQL_ADMIN_SECRET}
      HASURA_ENDPOINT: http://graphql-engine:8080
    depends_on:
      - graphql-engine
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  siws-service:
    build:
      context: ./services/siws-service
      dockerfile: Dockerfile
    ports:
      - "3031:3031"
    environment:
      SIWS_SERVICE_PORT: 3031
    depends_on:
      - graphql-engine
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  data-connector-agent:
    image: hasura/graphql-data-connector:v2.28.0
    restart: always
    ports:
      - 8081:8081
    environment:
      QUARKUS_LOG_LEVEL: ERROR # FATAL, ERROR, WARN, INFO, DEBUG, TRACE
      ## https://quarkus.io/guides/opentelemetry#configuration-reference
      QUARKUS_OPENTELEMETRY_ENABLED: "false"
      ## QUARKUS_OPENTELEMETRY_TRACER_EXPORTER_OTLP_ENDPOINT: http://jaeger:4317
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/api/v1/athena/health"]
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 5s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  caddy:
    build:
      context: .
      dockerfile: "./dockerfiles/caddy.dockerfile"
    restart: unless-stopped
    network_mode: host
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  caddy_data:
  caddy_config:
